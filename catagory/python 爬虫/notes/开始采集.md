到目前为止，本书的例子都只是处理单个静态页面，只能算是人为简化的例子（使用作者的网站页面)。从本章开始，我们会看到一些现实问题，需要用爬虫遍历多个页面甚至多 个网站。
之所以叫网络爬虫(Web crawler)是因为它们可以沿着网络爬行。它们的本质就是一种递 归方式。为了找到 URL 链接，它们必须首先获取网页内容，检查这个页面的内容，再寻 找另一个 URL，然后获取 URL 对应的网页内容，不断循环这一过程。
不过要注意的是:你可以这样重复采集网页，但并不意味着你一直都应该这么做。当你需 要的所有数据都在一个页面上时，前面例子中的爬虫就足以解决问题了。使用网络爬虫的 时候，你必须非常谨慎地考虑需要消耗多少网络流量，还要尽力思考能不能让采集目标的 服务器负载更低一些。

# 3.1 遍历单个域名
即使你没听说过“维基百科六度分隔理论”，也很可能听过“凯文· 贝肯(Kevin Bacon) 的六度分隔值游戏”。在这两个游戏中，都是把两个不相干的主题(维基百科里是用词条 之间的连接，凯文 · 贝肯的六度分隔值游戏是用出现在同一部电影中的演员来连接)用一 个总数不超过六条的主题连接起来(包括原来的两个主题)。
比如，埃里克 · 艾德尔和布兰登 · 弗雷泽都出现在电影《骑警杜德雷》里，布兰登 · 弗 雷泽又和凯文·贝肯都出现在电影《我呼吸的空气》里。1 因此，根据这两个条件，从埃
里克· 艾德尔到凯文·贝肯的链条主题长度只有 3。
我们将在本节创建一个项目来实现“维基百科六度分隔理论”的查找方法。也就是说，我们 要实现从埃里克· 艾德尔的词条页面(https://en.wikipedia.org/wiki/Eric_Idle)开始，经过最 少的链接点击次数找到凯文· 贝肯的词条页面(https://en.wikipedia.org/wiki/Kevin_Bacon)。

# 这么做对维基百科的服务器负载有多大影响 ?
根据维基媒体基金会(维基百科归属的组织)的统计，网站每秒钟会收到大约 2500
次点击，其中超过 99% 的点击都是指向维基百科域名(详情请见“维基媒体统计图” (Wikimedia in Figures)里的“流量数据”(Traffic Volume)部分内容，https://meta. wikimedia.org/wiki/Wikimedia_in_figures_-_Wikipedia#Traffic_volume)。因为网站流量 很大，所以你的网络爬虫不可能对维基百科的负载有显著影响。不过，如果你频繁地 运行本书的代码，或者自己在做项目采集维基百科的词条，那么希望你能够向维基媒 体基金会提供一点捐赠(https://wikimediafoundation.org/wiki/Ways_to_Give)——即 使是很少的钱来补偿你占用的服务器资源，算是帮助维基百科这个教育资源供其他人
使用。
